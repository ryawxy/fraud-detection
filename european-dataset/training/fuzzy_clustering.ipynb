{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-21T13:14:08.851446Z",
     "start_time": "2025-07-21T13:13:59.955411Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skfuzzy import cmeans\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# # Generate synthetic transaction data (replace with real dataset)\n",
    "# np.random.seed(42)\n",
    "# n_samples = 1000\n",
    "# data = {\n",
    "#     'amount': np.random.normal(100, 50, n_samples),\n",
    "#     'time': np.random.uniform(0, 24, n_samples),\n",
    "#     'location_score': np.random.uniform(0, 1, n_samples),\n",
    "#     'is_fraud': np.zeros(n_samples)  # 0 for non-fraud, 1 for fraud\n",
    "# }\n",
    "# # Simulate 5% fraud cases\n",
    "# data['is_fraud'][950:] = 1\n",
    "# data['amount'][950:] *= 5  # Fraudulent transactions have higher amounts\n",
    "# df = pd.DataFrame(data)\n",
    "#\n",
    "# # Preprocess data\n",
    "# X = df[['amount', 'time', 'location_score']].values\n",
    "# y = df['is_fraud'].values\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "#\n",
    "# # Handle class imbalance with undersampling\n",
    "# rus = RandomUnderSampler(random_state=42)\n",
    "# X_resampled, y_resampled = rus.fit_resample(X_scaled, y)\n",
    "\n",
    "\n",
    "X = pd.read_csv('/Users/raya/Desktop/fraud-detection/european-dataset/data/processed/X.csv')\n",
    "y = pd.read_csv('/Users/raya/Desktop/fraud-detection/european-dataset/data/processed/y.csv')['Class']\n",
    "# Apply Fuzzy C-Means clustering\n",
    "n_clusters = 3  # Tune based on data\n",
    "cntr, u, u0, d, jm, p, fpc = cmeans(\n",
    "    data=X.T, c=n_clusters, m=2, error=0.005, maxiter=1000, init=None\n",
    ")\n",
    "\n",
    "# Get membership scores and cluster assignments\n",
    "membership_scores = u.T\n",
    "cluster_labels = np.argmax(membership_scores, axis=1)\n",
    "\n",
    "# Flag suspicious transactions (low membership scores)\n",
    "threshold = 0.3  # Adjust based on experimentation\n",
    "is_suspicious = np.max(membership_scores, axis=1) < threshold\n",
    "\n",
    "# Prepare data for neural network (suspicious cases)\n",
    "suspicious_indices = np.where(is_suspicious)[0]\n",
    "X_suspicious = X[suspicious_indices]\n",
    "y_suspicious = y[suspicious_indices]\n",
    "\n",
    "# Split data for training neural network\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_suspicious, y_suspicious, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train neural network classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict fraud on suspicious cases\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Combine results\n",
    "df_resampled = pd.DataFrame(X, columns=['amount', 'time', 'location_score'])\n",
    "df_resampled['cluster'] = cluster_labels\n",
    "df_resampled['is_suspicious'] = is_suspicious\n",
    "df_resampled['is_fraud'] = y\n",
    "df_resampled['nn_pred'] = np.nan\n",
    "df_resampled.loc[suspicious_indices[np.where(np.isin(suspicious_indices, np.where(is_suspicious)[0]))], 'nn_pred'] = mlp.predict(X_suspicious)\n",
    "\n",
    "# Output results\n",
    "print(\"Fraud Detection Results (first 10 rows):\")\n",
    "print(df_resampled.head(10))\n",
    "print(\"\\nNumber of suspicious cases:\", np.sum(is_suspicious))\n",
    "print(\"\\nNeural Network Accuracy on Suspicious Cases:\", mlp.score(X_test, y_test))\n",
    "\n",
    "# Save results\n",
    "df_resampled.to_csv('fraud_detection_hybrid_results.csv', index=False)"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [284506, 0]",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 56\u001B[39m\n\u001B[32m     53\u001B[39m y_suspicious = y[suspicious_indices]\n\u001B[32m     55\u001B[39m \u001B[38;5;66;03m# Split data for training neural network\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m56\u001B[39m X_train, X_test, y_train, y_test = \u001B[43mtrain_test_split\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     57\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX_suspicious\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_suspicious\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0.2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m42\u001B[39;49m\n\u001B[32m     58\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;66;03m# Train neural network classifier\u001B[39;00m\n\u001B[32m     61\u001B[39m mlp = MLPClassifier(hidden_layer_sizes=(\u001B[32m10\u001B[39m,), max_iter=\u001B[32m1000\u001B[39m, random_state=\u001B[32m42\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    210\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    211\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    212\u001B[39m         skip_parameter_validation=(\n\u001B[32m    213\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    214\u001B[39m         )\n\u001B[32m    215\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    218\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    219\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    222\u001B[39m     msg = re.sub(\n\u001B[32m    223\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    224\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    225\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    226\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_split.py:2848\u001B[39m, in \u001B[36mtrain_test_split\u001B[39m\u001B[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001B[39m\n\u001B[32m   2845\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m n_arrays == \u001B[32m0\u001B[39m:\n\u001B[32m   2846\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mAt least one array required as input\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m2848\u001B[39m arrays = \u001B[43mindexable\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2850\u001B[39m n_samples = _num_samples(arrays[\u001B[32m0\u001B[39m])\n\u001B[32m   2851\u001B[39m n_train, n_test = _validate_shuffle_split(\n\u001B[32m   2852\u001B[39m     n_samples, test_size, train_size, default_test_size=\u001B[32m0.25\u001B[39m\n\u001B[32m   2853\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:532\u001B[39m, in \u001B[36mindexable\u001B[39m\u001B[34m(*iterables)\u001B[39m\n\u001B[32m    502\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Make arrays indexable for cross-validation.\u001B[39;00m\n\u001B[32m    503\u001B[39m \n\u001B[32m    504\u001B[39m \u001B[33;03mChecks consistent length, passes through None, and ensures that everything\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    528\u001B[39m \u001B[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001B[39;00m\n\u001B[32m    529\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    531\u001B[39m result = [_make_indexable(X) \u001B[38;5;28;01mfor\u001B[39;00m X \u001B[38;5;129;01min\u001B[39;00m iterables]\n\u001B[32m--> \u001B[39m\u001B[32m532\u001B[39m \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    533\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:475\u001B[39m, in \u001B[36mcheck_consistent_length\u001B[39m\u001B[34m(*arrays)\u001B[39m\n\u001B[32m    473\u001B[39m uniques = np.unique(lengths)\n\u001B[32m    474\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) > \u001B[32m1\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m475\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    476\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    477\u001B[39m         % [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[32m    478\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: Found input variables with inconsistent numbers of samples: [284506, 0]"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
